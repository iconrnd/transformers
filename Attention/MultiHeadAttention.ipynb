{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85efc347-fcd8-4849-afdd-0846161c0815",
   "metadata": {},
   "source": [
    "## MultiHeadAttention adapted from \n",
    "### https://machinelearningmastery.com/how-to-implement-multi-head-attention-from-scratch-in-tensorflow-and-keras/\n",
    "\n",
    "## Crucially in the above no explicit mention is made about the relation between Q, K, V projection dimensions and the number of attention heads.\n",
    "\n",
    "## Below we make that detail explicit by defining these dimensions as multiples of the attention heads count.\n",
    "\n",
    "## This works by performing one long rectangular matrix multiplications for the Q, K, V projections and then chopping rows into equal size parts as inputs for individual heads. This is why the number of heads must divide d_k, d_v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52522426-2fab-49fc-b1cc-c322dad4aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3a52f1-3682-4eba-9bb0-bfc08c5c0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "        scores = tf.matmul(queries, keys, transpose_b=True) / tf.sqrt(tf.cast(d_k, tf.float32))\n",
    "\n",
    "        # Effectively zeroing entries in softmax\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask \n",
    "\n",
    "        weights = tf.nn.softmax(scores)\n",
    "\n",
    "        return tf.matmul(weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5de978b4-c4e6-4030-9fcc-22cc5a51bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "\n",
    "        self.attention = DotProductAttention()\n",
    "\n",
    "        self.heads = h\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.W_q = tf.keras.layers.Dense(d_k)\n",
    "        self.W_k = tf.keras.layers.Dense(d_k)\n",
    "        self.W_v = tf.keras.layers.Dense(d_v)\n",
    "        # Layer output will produce model's working shape \n",
    "        # - the embedding dimensionality\n",
    "        self.W_o = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            # Tensor shape after reshaping and transposing: (batch_size, heads, seq_length, -1)\n",
    "            x = tf.reshape(x, shape=(tf.shape(x)[0], tf.shape(x)[1], heads, -1))\n",
    "            x = tf.transpose(x, perm=(0, 2, 1, 3))\n",
    "        else:\n",
    "            # Reverting the reshaping and transposing operations: (batch_size, seq_length, d_model)\n",
    "            x = tf.transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = tf.reshape(x, shape=(tf.shape(x)[0], tf.shape(x)[1], -1))\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, flag=True)\n",
    "        print(f'Reshaped query partitioned into heads: {q_reshaped.shape}')\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, flag=True)\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, flag=True)\n",
    "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
    "        output = self.reshape_tensor(o_reshaped, self.heads, flag=False)\n",
    "\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03408b50-dce2-436f-85f9-3f30eb917908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of self-attention heads\n",
    "h = 8 \n",
    "\n",
    "# Dimensionality of the linearly projected queries and keys\n",
    "# Individual head will get 16-dimensional input\n",
    "d_k = 16 * h  \n",
    "d_v = 16 * h \n",
    "\n",
    "# Dimensionality of the model sub-layers' outputs\n",
    "d_model = 512  \n",
    "batch_size = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ab6fb38-a249-43e3-841d-80281de7d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum length of the input sequence\n",
    "input_seq_length = 5  \n",
    " \n",
    "queries = np.random.random((batch_size, input_seq_length, d_k))\n",
    "keys = np.random.random((batch_size, input_seq_length, d_k))\n",
    "values = np.random.random((batch_size, input_seq_length, d_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad462f8f-0962-415d-832f-74d39b759848",
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a314fdff-ccda-46c8-af4c-2f443b20a1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped query partitioned into heads: (1, 8, 5, 16)\n",
      "tf.Tensor(\n",
      "[[[-0.06934756 -0.4272185  -0.7013557  ... -0.18155214 -0.04901038\n",
      "    0.10685071]\n",
      "  [-0.06753655 -0.4271417  -0.6974434  ... -0.17985624 -0.04874355\n",
      "    0.10335528]\n",
      "  [-0.07192618 -0.42755052 -0.70126486 ... -0.1846404  -0.04992645\n",
      "    0.10626048]\n",
      "  [-0.07006095 -0.42346823 -0.6988238  ... -0.18033272 -0.04631981\n",
      "    0.10505362]\n",
      "  [-0.06831628 -0.42368662 -0.7011584  ... -0.18153885 -0.04925524\n",
      "    0.10744631]]], shape=(1, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(multihead_attention(queries, keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73433f38-fdba-48ba-ac57-1c8e6c74f3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3966ec4-4f47-4229-a9b6-82908c662a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
