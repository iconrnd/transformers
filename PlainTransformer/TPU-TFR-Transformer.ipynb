{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8057ffa-b79c-4ba1-89d7-66205dc5f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7df8b-416b-4f63-93ad-583129932724",
   "metadata": {},
   "source": [
    "## TPU/GPU Strategy connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681273a-1b3f-40a4-af8d-44f6efc454e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    # For use with TPU:\n",
    "\n",
    "    # Detect TPUs\n",
    "    \n",
    "    # Locate TPUs on the network\n",
    "    # tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
    "    \n",
    "    # TPUStrategy contains the necessary distributed training code that will work on TPUs \n",
    "    # with their 8 compute cores\n",
    "    # strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    \n",
    "    # Multi GPU training\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"]) #, \"/gpu:1\"])\n",
    "\n",
    "except ValueError: # If TPU or GPU is not available\n",
    "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe0b77e-51ae-4afa-ac28-bc924d56af4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of accelerators: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of accelerators: {strategy.num_replicas_in_sync}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4029e-de42-4993-8593-d83567550a3b",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c2f54a-a020-42d7-83cf-06a5ab3d4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5511ca8c-5a72-4e6c-991a-0929bcb2ab46",
   "metadata": {},
   "source": [
    "## Initial Data Processing: EN-ES translation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e082c42-012d-4616-8059-a9c1be115fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\", extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6591186b-3e5c-4d6f-9e33-a762eb576931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = (Path(path).with_name(\"spa-eng\")/\"spa.txt\").read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af13e978-6cf3-49ed-93f3-9386055d2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('¡','').replace('¿','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d5e8be-fecb-482d-91f4-fd0e4c4575b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation pairs are separated by tabs\n",
    "pairs = [line.split('\\t') for line in text.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b870b17d-4cff-47a5-b0fe-0a380ba99b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Go.', 'Ve.'],\n",
       " ['Go.', 'Vete.'],\n",
       " ['Go.', 'Vaya.'],\n",
       " ['Go.', 'Váyase.'],\n",
       " ['Hi.', 'Hola.'],\n",
       " ['Run!', 'Corre!'],\n",
       " ['Run.', 'Corred.'],\n",
       " ['Who?', 'Quién?'],\n",
       " ['Fire!', 'Fuego!'],\n",
       " ['Fire!', 'Incendio!']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a94d0a0-9930-40f2-a716-a238bfd626aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inplace shuffling the whole dataset\n",
    "np.random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc82be9-b78b-4dde-896e-92a5926206d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_en, sentences_es = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "416b396c-bb23-46ea-95eb-34f635c69005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding based on the first 1000 words\n",
    "vocab_size = 1000\n",
    "\n",
    "# Max sentence length counted in tokes, so whole words here\n",
    "max_length = 50\n",
    "\n",
    "# Ebedding dimension\n",
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15e1d6-a6e7-4ea0-84c5-f84c243527d3",
   "metadata": {},
   "source": [
    "## Text tokenizer adaptation\n",
    "\n",
    "## Note: these two layers are for simplicity defined here at the level of dataset preparation\n",
    "## and used inside the transformer class below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14a6d42-cdfe-46f1-9b68-45136269f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer_en = tf.keras.layers.TextVectorization(vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(vocab_size, output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43000f44-69ad-4b06-86fc-a6eb4bad6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer_en.adapt(sentences_en)\n",
    "text_vec_layer_es.adapt([f'startofseq {s} endofseq' for s in sentences_es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48618fd9-2787-43aa-89bc-06c393e46524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_en.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb105a02-abd9-440c-998b-6129f0204586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_es.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e274617-c162-4bbb-a7af-871ca224c7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I heard every word.',)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_en[99999:100_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13790c5-8186-4db5-8be6-cc3c4335d833",
   "metadata": {},
   "source": [
    "## Initial raw data split and target tokenization\n",
    "\n",
    "## We leave inputs in natural form to be able to input plain sentences at inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3e610d6-84f2-49ae-9bae-cedf86fc0c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118964"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f29b3406-1b4c-4326-84fc-64fa7ada1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CNT = 100000\n",
    "VALID_CNT = len(sentences_en) - TRAIN_CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2134c74-b86f-40a5-9484-a5327a5448f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sentences_en[:TRAIN_CNT]\n",
    "X_valid = sentences_en[TRAIN_CNT:]\n",
    "\n",
    "# Data shifter by one token for teacher forcing\n",
    "X_train_dec = [f'startofseq {s}' for s in sentences_es[:TRAIN_CNT]]\n",
    "X_valid_dec = [f'startofseq {s}' for s in sentences_es[TRAIN_CNT:]]\n",
    "\n",
    "# The last predicted token must indicate sentence end\n",
    "Y_train = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[:TRAIN_CNT]]).numpy()\n",
    "Y_valid = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[TRAIN_CNT:]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5518560a-0391-4a8a-9f9a-7a122b093e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startofseq Deja que llame a Tom.', 'startofseq Lo oí todo.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dec[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac93ce58-975a-4bfc-8d9a-1841cfb92732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,  14,   1, ...,   0,   0,   0],\n",
       "       [ 42, 175,  22, ...,   0,   0,   0],\n",
       "       [ 35,   7,  68, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [171,   5,   8, ...,   0,   0,   0],\n",
       "       [440,   5,   1, ...,   0,   0,   0],\n",
       "       [ 17, 738,  55, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94c8f839-dca7-490a-85cf-ffbf6a45c47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35,   1,   6, ...,   0,   0,   0],\n",
       "       [ 46,   1,   3, ...,   0,   0,   0],\n",
       "       [ 26, 448,   6, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 46,   5,  17, ...,   0,   0,   0],\n",
       "       [  8,   7,  48, ...,   0,   0,   0],\n",
       "       [ 20, 395,  78, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e615bf94-381f-444e-9dff-3bf2acc187e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_valid[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9b233-f40d-4c8c-8eac-8664ac34ee41",
   "metadata": {},
   "source": [
    "## TFRecords Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9d2596f-7ca5-49f0-9233-c2b9c238dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where tfrecords will be stored\n",
    "tfrecords_dir = 'tfrecords'\n",
    "\n",
    "# Train val split\n",
    "\n",
    "# Defining how many samples will be stored in a single TFRecords file\n",
    "samples_per_tfrecord = 4096\n",
    "\n",
    "# Training and validation sets\n",
    "tfrecords_cnt_trn = TRAIN_CNT // samples_per_tfrecord\n",
    "tfrecords_cnt_val = VALID_CNT // samples_per_tfrecord\n",
    "\n",
    "# Adding potential remaining samples into one extra TFRecords file\n",
    "if tfrecords_cnt_trn % samples_per_tfrecord:\n",
    "    tfrecords_cnt_trn += 1\n",
    "\n",
    "if tfrecords_cnt_val % samples_per_tfrecord:\n",
    "    tfrecords_cnt_val += 1\n",
    "    \n",
    "if not os.path.exists(tfrecords_dir):\n",
    "    os.makedirs(f'{tfrecords_dir}/train')\n",
    "    os.makedirs(f'{tfrecords_dir}/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29af8a57-dad7-4d89-86f1-424a54fa9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String input sentences\n",
    "def bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array)\n",
    "    \n",
    "  return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c753cfe5-a7a7-4096-8ee6-2f9d586e561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(txt_en, txt_es, label):\n",
    "    serialized_label = serialize_array(label)\n",
    "    feature = {\n",
    "        \"encoder_input\": bytes_feature(bytes(txt_en, 'utf-8')),\n",
    "        \"decoder_input\": bytes_feature(bytes(txt_es, 'utf-8')),\n",
    "        \"label\": bytes_feature(serialized_label),\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12add3da-f1bd-4fcd-b509-9600e7c0ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodes example stored in a TFR and returns it as a readable sample\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_spec = {\n",
    "        \"encoder_input\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "        \"decoder_input\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(example, feature_spec)\n",
    "    label_array = example['label']\n",
    "    example['label'] = tf.io.parse_tensor(label_array, out_type=tf.int64) # restore array from byte string\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52d3bd1b-f588-4c43-a7bf-ceaea8efeb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 s, sys: 1.01 s, total: 17 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "assert len(X_train) == len(X_train_dec), \"Encoder/Decoder datasets don't match\"\n",
    "\n",
    "for tfrec_id in range(tfrecords_cnt_trn):\n",
    "\n",
    "    txt_en_batch = X_train[tfrec_id * samples_per_tfrecord : (tfrec_id + 1 ) * samples_per_tfrecord]\n",
    "    txt_es_batch = X_train_dec[tfrec_id * samples_per_tfrecord : (tfrec_id + 1 ) * samples_per_tfrecord]\n",
    "    Y_train_batch = Y_train[tfrec_id * samples_per_tfrecord : (tfrec_id + 1 ) * samples_per_tfrecord]\n",
    "    \n",
    "    with tf.io.TFRecordWriter(\n",
    "        tfrecords_dir + \"/train/tfrecord_%.6i.tfrec\" % (tfrec_id)\n",
    "    ) as writer:\n",
    "    \n",
    "        for i in range(len(txt_en_batch)):\n",
    "    \n",
    "            example = create_example(txt_en_batch[i], txt_es_batch[i], Y_train_batch[i])\n",
    "            \n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "for tfrec_id in range(tfrecords_cnt_val):\n",
    "\n",
    "    txt_en_batch = X_valid[tfrec_id * samples_per_tfrecord : (tfrec_id + 1 ) * samples_per_tfrecord]\n",
    "    txt_es_batch = X_valid_dec[tfrec_id * samples_per_tfrecord : (tfrec_id + 1 ) * samples_per_tfrecord]\n",
    "    Y_val_batch = Y_valid[tfrec_id * samples_per_tfrecord : (tfrec_id + 1 ) * samples_per_tfrecord]\n",
    "    \n",
    "    with tf.io.TFRecordWriter(\n",
    "        tfrecords_dir + \"/valid/tfrecord_%.6i.tfrec\" % (tfrec_id)\n",
    "    ) as writer:\n",
    "    \n",
    "        for i in range(len(txt_en_batch)):\n",
    "    \n",
    "            example = create_example(txt_en_batch[i], txt_es_batch[i], Y_val_batch[i])\n",
    "            \n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3e532-d72e-4475-b167-1c156bc023cc",
   "metadata": {},
   "source": [
    "## Inspect parsed dataset samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84b442d1-f4fc-45f8-b62c-29f3117bc2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(\"tfrecords\" + \"/valid/tfrecord_000000.tfrec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9a2fd0f-674f-4532-af2c-d6b061cf57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset = raw_dataset.map(parse_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74ee800b-9a6a-4b81-b629-7fc281dd05a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec={'decoder_input': TensorSpec(shape=(), dtype=tf.string, name=None), 'encoder_input': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=<unknown>, dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02cda15d-a045-4412-96d2-80e294d746d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'decoder_input': <tf.Tensor: shape=(), dtype=string, numpy=b'startofseq Yo asistir\\xc3\\xa9 a la conferencia.'>, 'encoder_input': <tf.Tensor: shape=(), dtype=string, numpy=b'I will go to the meeting.'>, 'label': <tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
      "array([35,  1,  6,  9,  1,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])>}\n"
     ]
    }
   ],
   "source": [
    "for instance in parsed_dataset.take(1):\n",
    "  print()\n",
    "  print(instance) # print parsed example messages with restored arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a14df06-0a3a-44f4-8313-d9ef4f440c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample(features):\n",
    "    features['label'].set_shape([50])\n",
    "    return (features['encoder_input'], features['decoder_input']), features['label']#[tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc0ec733-418c-447a-87ec-a60b4f2047bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames, batch_size):\n",
    "    \n",
    "    dataset = (\n",
    "    tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "        .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "        .map(prepare_sample, num_parallel_calls=AUTOTUNE)\n",
    "        .shuffle(10 * batch_size)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8706b0b-f7ef-4992-9500-6a12822a6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = tf.io.gfile.glob(f'{tfrecords_dir}/train/*.tfrec')\n",
    "valid_filenames = tf.io.gfile.glob(f'{tfrecords_dir}/valid/*.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6c2ed31-035f-49f7-af53-1362123ed804",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(train_filenames, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c6feb61-dbd6-46e6-8b87-84fcebba49eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 50), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e88bebc5-6481-4b49-a82d-ebdf42c73ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Have you ever plucked a chicken?'], dtype=object)>,\n",
       "  <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
       "  array([b'startofseq Has desplomado a una gallina alguna vez?'],\n",
       "        dtype=object)>),\n",
       " <tf.Tensor: shape=(1, 50), dtype=int64, numpy=\n",
       " array([[129,   1,   6,  18,   1, 194,  70,   3,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d990c87-aa6a-41dc-a52f-85e0d91d81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = math.ceil(TRAIN_CNT / BATCH_SIZE)\n",
    "validation_steps = math.ceil(VALID_CNT / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533d888a-32a8-4c5e-891c-305116ef333f",
   "metadata": {},
   "source": [
    "## Datasets creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e55e6cef-d381-48c4-9e80-14f89d487d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(train_filenames, BATCH_SIZE)\n",
    "val_ds = get_dataset(valid_filenames, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d15d6-0eb5-4c82-9d52-5902460a15ef",
   "metadata": {},
   "source": [
    "## Fixed positional encoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90df6a33-3758-48f6-9120-d8beb2c61a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_length, embed_size, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert embed_size % 2 == 0, \"embed_size must be even\"\n",
    "        p, i = np.meshgrid(np.arange(max_length),\n",
    "                           2 * np.arange(embed_size // 2))\n",
    "        pos_emb = np.empty((1, max_length, embed_size))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10_000 ** (i / embed_size)).T\n",
    "        # Here we use the same values for i as above, since for odd embedding posiitons\n",
    "        # we use (i-1) as the exponent value, which evaluates to the value i of the even case above\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10_000 ** (i / embed_size)).T\n",
    "        self.pos_encodings = tf.constant(pos_emb.astype(self.dtype))\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_max_length = tf.shape(inputs)[1]\n",
    "        return inputs + self.pos_encodings[:, :batch_max_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a987e-ce43-445f-9dbc-e21c4ace2967",
   "metadata": {},
   "source": [
    "## The Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "276f5d2c-9958-4932-bb49-ba8bb96ecd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 vocab_size=1000, # Number of tokens\n",
    "                 embed_size=128, # Text embedding dimension\n",
    "                 max_length=50, # Max sentence length\n",
    "                 N=2, # Number of Transformer layers\n",
    "                 num_heads=8, # Attention heads number\n",
    "                 dropout_rate=0.1,\n",
    "                 n_units=128, # Width of dense layers\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.max_length = max_length \n",
    "        self.N = N\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_units = n_units\n",
    "\n",
    "        self.encoder_embedding_layer = tf.keras.layers.Embedding(self.vocab_size, self.embed_size, mask_zero=True)\n",
    "        self.decoder_embedding_layer = tf.keras.layers.Embedding(self.vocab_size, self.embed_size, mask_zero=True)\n",
    "        self.pos_embed_layer = PositionalEncoding(self.max_length, self.embed_size)\n",
    "        self.attn_layer_enc = tf.keras.layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_size, dropout=self.dropout_rate)\n",
    "        self.norm_layer = tf.keras.layers.LayerNormalization()\n",
    "        self.add_layer = tf.keras.layers.Add()\n",
    "        self.dense_enc_0 = tf.keras.layers.Dense(self.n_units, activation=\"relu\")\n",
    "        self.dense_enc_1 = tf.keras.layers.Dense(self.embed_size)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "        self.attn_layer_dec_0 = tf.keras.layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_size, dropout=self.dropout_rate)\n",
    "        self.attn_layer_dec_1 = tf.keras.layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_size, dropout=self.dropout_rate)\n",
    "        self.dense_dec_0 = tf.keras.layers.Dense(self.n_units, activation=\"relu\")\n",
    "        self.dense_dec_1 = tf.keras.layers.Dense(self.embed_size)\n",
    "        self.dense_output = tf.keras.layers.Dense(self.vocab_size, activation=\"softmax\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        encoder_inputs = inputs[0]\n",
    "        decoder_inputs = inputs[1]\n",
    "\n",
    "        # Encoder and decoder inputs tokenization\n",
    "        # At this point tokenizers are already adapted above\n",
    "        encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "        decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
    "\n",
    "        encoder_input_ids = tf.cast(encoder_input_ids, tf.float32)\n",
    "        decoder_input_ids = tf.cast(decoder_input_ids, tf.float32)\n",
    "\n",
    "        encoder_embeddings = self.encoder_embedding_layer(encoder_input_ids)\n",
    "        decoder_embeddings = self.decoder_embedding_layer(decoder_input_ids)\n",
    "\n",
    "        batch_max_len_dec = tf.shape(decoder_embeddings)[1]\n",
    "\n",
    "        encoder_in = self.pos_embed_layer(encoder_embeddings)\n",
    "        decoder_in = self.pos_embed_layer(decoder_embeddings)\n",
    "\n",
    "        encoder_pad_mask = tf.math.not_equal(encoder_input_ids, 0)[:, tf.newaxis]\n",
    "            \n",
    "        # Input data\n",
    "        Z = encoder_in\n",
    "\n",
    "        # Encoder block\n",
    "        for _ in range(self.N):\n",
    "            skip = Z\n",
    "            Z = self.attn_layer_enc(Z, value=Z, attention_mask=encoder_pad_mask)\n",
    "            Z = self.norm_layer(self.add_layer([Z, skip]))           \n",
    "            skip = Z\n",
    "            Z = self.dense_enc_0(Z)\n",
    "            Z = self.dense_enc_1(Z)\n",
    "            Z = self.dropout(Z)\n",
    "            Z = self.norm_layer(self.add_layer([Z, skip]))\n",
    "\n",
    "        decoder_pad_mask = tf.math.not_equal(decoder_input_ids, 0)[:, tf.newaxis]\n",
    "        causal_mask = tf.linalg.band_part(\n",
    "                tf.ones((batch_max_len_dec, batch_max_len_dec), tf.bool), -1, 0)\n",
    "\n",
    "        encoder_outputs = Z\n",
    "        Z = decoder_in\n",
    "\n",
    "        for _ in range(self.N):\n",
    "            skip = Z\n",
    "            Z = self.attn_layer_dec_0(Z, value=Z, attention_mask=causal_mask & decoder_pad_mask)\n",
    "            Z = self.norm_layer(self.add_layer([Z, skip]))\n",
    "            skip = Z\n",
    "            # Cross-Attenion: Query from decoder, Key and Value from Encoder\n",
    "            Z = self.attn_layer_dec_1(Z, value=encoder_outputs, attention_mask=encoder_pad_mask)\n",
    "            Z = self.norm_layer(self.add_layer([Z, skip]))\n",
    "            skip = Z\n",
    "            Z = self.dense_dec_0(Z)\n",
    "            Z = self.dense_dec_1(Z)\n",
    "            Z = self.norm_layer(self.add_layer([Z, skip]))\n",
    "\n",
    "        Y_proba = self.dense_output(Z)\n",
    "\n",
    "        # Patching wrong weights shape used in loss\n",
    "        Y_proba._keras_mask = Y_proba._keras_mask[:, :, tf.newaxis]\n",
    "\n",
    "        return Y_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90f04ebc-0533-4e3f-900e-23aea61c6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = Transformer()\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=\"nadam\",\n",
    "                  metrics=[\"accuracy\"], )\n",
    "                  #run_eagerly=True)\n",
    "                  #jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c1cc6-b4aa-4b5d-8656-033cdcfd6af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   epochs=1,\n",
    "                   validation_data=val_ds,\n",
    "                   validation_steps=validation_steps,)\n",
    "                   #verbose=1,)\n",
    "                   #callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495dc15-397b-4150-a073-aaf5c7228bf7",
   "metadata": {},
   "source": [
    "## Inference (after just one epoch, no expectations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1478611d-2179-48fe-b7fa-7bd0e675724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence_en):\n",
    "    translation = \"\"\n",
    "    for word_idx in range(max_length):\n",
    "        X = np.array([sentence_en])\n",
    "        X_dec = np.array([\"startofseq \" + translation])\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
    "        if predicted_word == 'endofseq':\n",
    "            break\n",
    "        translation += \" \" + predicted_word\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fda3d2b7-d998-4d49-9cb8-83e6e4d19453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta el fútbol'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like soccer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
